# ğŸ§  Text Search Engine Built from Scratch

This project is a search engine backend implemented completely from scratch to learn **Data Structures & Algorithms in a real system**.

It supports:

- ğŸ” Keyword search  
- ğŸ”— Multi-word boolean queries (AND / OR)  
- ğŸ“Š Relevance ranking (Top-K results using heap)  
- ğŸŒ³ Autocomplete (Trie / Prefix Tree)  
- âœï¸ Fuzzy search (typo tolerance using Edit Distance + Dynamic Programming)

No external search libraries are used. Everything is implemented manually.

---

# ğŸ“¦ How the System Works

High-level flow:

```
Raw Text
   â†“
Tokenizer
   â†“
Inverted Index + Trie
   â†“
Search Layer (Boolean + Ranking + Fuzzy)
```

Each component has a single responsibility and is independently testable.

---

# ğŸ“ Document Handling

- Documents are plain text
- Stored in memory
- Each document receives a numeric ID (starting from 1)
- Document ingestion updates:
  - Inverted Index
  - Trie (for autocomplete)

---

# ğŸ”¤ Tokenization Rules

All text is normalized using consistent rules:

- Convert to lowercase  
- Remove punctuation  
- Split by whitespace  

### Examples

| Raw Input | Tokens |
|------------|--------|
| "The quick brown fox jumps!" | `['the', 'quick', 'brown', 'fox', 'jumps']` |
| "Hello, world? Is anyone there?" | `['hello', 'world', 'is', 'anyone', 'there']` |
| "Data science is 100% awesome." | `['data', 'science', 'is', '100', 'awesome']` |
| "It's a beautiful day in NYC." | `['its', 'a', 'beautiful', 'day', 'in', 'nyc']` |

Tokenizer is the single source of truth for text normalization.

---

# ğŸ“š Inverted Index

Core structure:

```
token â†’ set of document IDs
```

Example:

| Word | Document IDs |
|------|---------------|
| the  | [1, 2] |
| cat  | [1] |
| sat  | [1, 2] |
| dog  | [2] |

This allows fast lookup without scanning all documents.

---

# ğŸš€ Project Phases

The system was built step-by-step to progressively introduce DSA concepts.

---

## âœ… Phase 1 â€” Core Search Engine

Implemented:

- In-memory document storage  
- Tokenizer  
- Inverted index  
- Naive linear search  
- Indexed search  

Goal: Understand indexing vs scanning.

Concepts used:
- Hash maps  
- Sets  
- Time complexity comparison  

---

## âœ… Phase 2 â€” Boolean Queries (AND / OR)

Added support for:

- Multi-word queries  
- AND logic (default)  
- OR logic (explicit using "or")  

Examples:

```
python search
python OR data
```

Concepts used:
- Set intersection  
- Set union  
- Query parsing  

---

## âœ… Phase 3 â€” Relevance Ranking & Top-K

Added ranking using **Term Frequency (TF)**.

- Score = number of query token occurrences in document  
- Results returned in ranked order  
- Top-K implemented using a min-heap  
- Avoids full sorting  

Concepts used:
- Heaps (priority queues)  
- Top-K optimization  

---

## âœ… Phase 4 â€” Autocomplete (Trie)

Implemented prefix-based autocomplete using a **Trie (Prefix Tree)**.

Features:

- Character-level tree  
- DFS traversal  
- Alphabetical suggestions  
- Optional limit (`k`)  

Example:

```
py â†’ python, pytest, pyramid
```

Concepts used:
- Trees  
- DFS  
- Prefix optimization  

---

## âœ… Phase 5 â€” Fuzzy Search (Edit Distance + DP)

Added typo tolerance using **Levenshtein Edit Distance**.

Behavior:

- If exact search returns no results  
- System finds similar tokens within a distance threshold  
- Boolean logic preserved  
- Ranking still applied  

Examples:

```
pythn â†’ python
srch  â†’ search
```

Concepts used:
- Dynamic Programming  
- State transition tables  
- Algorithmic fallback strategies  

---

# ğŸ— Current Architecture

```
Storage        â†’ owns documents
Tokenizer      â†’ text â†’ tokens
InvertedIndex  â†’ token â†’ doc_ids
Trie           â†’ token prefixes â†’ tokens
Search Layer   â†’ AND / OR / ranking / fuzzy fallback
```

Each layer:

- Has a single responsibility  
- Is independently testable  
- Avoids mixing concerns  

---

# ğŸ§  DSA Concepts Covered

This project demonstrates practical usage of:

- Hash Maps  
- Sets  
- Trees (Trie)  
- DFS  
- Heaps  
- Dynamic Programming  
- Boolean logic processing  
- Performance optimization  

This is DSA applied inside a working system, not isolated exercises.

---

# ğŸ¯ Purpose

The goal of this project is to:

- Learn DSA by building real systems  
- Understand how search engines work internally  
- Connect algorithmic thinking with backend design  
- Build a strong, interview-ready project  
